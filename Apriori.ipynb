{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Apriori.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOs03r+gDruh3I/jfNg8uLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yash-Kamtekar/Optional_Assignment/blob/main/Apriori.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First import the libraries which will be useful."
      ],
      "metadata": {
        "id": "8XO520lwVmHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import combinations\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tr7Lb4qTreX7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "custom data set"
      ],
      "metadata": {
        "id": "_9WtFob4uAaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = {\n",
        "    1: [\"1\", \"3\", \"4\"],\n",
        "    2: [\"2\", \"3\", \"5\"],\n",
        "    3: [\"1\", \"2\", \"3\", \"5\"],\n",
        "    5: [\"2\", \"5\"],\n",
        "    6: [\"1\", \"3\", \"5\"]\n",
        "}"
      ],
      "metadata": {
        "id": "KbDHhDguuCbx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting minimum support and confidence value."
      ],
      "metadata": {
        "id": "i81JC1KMuFLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_support_count = 2\n",
        "min_confidence_value = 0.6"
      ],
      "metadata": {
        "id": "XY92hO59uJbG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to prune."
      ],
      "metadata": {
        "id": "GePTPHWfuJli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _pruning(current, previous, size):\n",
        "    final_keys = []\n",
        "    previous = [tuple(i) for i in previous]\n",
        "    for key in current:\n",
        "        FLAG = False\n",
        "        current_comb = list(combinations(key, size))\n",
        "        for i in current_comb:\n",
        "            if i in previous or i[::-1] in previous:\n",
        "                FLAG = True\n",
        "            else:\n",
        "                FLAG = False\n",
        "                break\n",
        "\n",
        "        if FLAG:\n",
        "            final_keys.append(key)\n",
        "\n",
        "    return final_keys"
      ],
      "metadata": {
        "id": "Hm9IA9pCuQAR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to calculate Support."
      ],
      "metadata": {
        "id": "FHug2kYxuQKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def support_value(itemset_keys_, transactions):\n",
        "    itemset = {key: 0 for key in itemset_keys_}\n",
        "\n",
        "    for keys in itemset_keys_:\n",
        "        for val in transactions.values():\n",
        "            if set(keys) & set(val) == set(keys):\n",
        "                itemset[keys] += 1\n",
        "    return itemset"
      ],
      "metadata": {
        "id": "cEiQaO5JuQTM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating frequent itemset."
      ],
      "metadata": {
        "id": "ZkQWkYxsue-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_frequent_itemset(size=None, transactions=None, itemset=None):\n",
        "    if size == 1:\n",
        "        itemset = Counter()\n",
        "\n",
        "        for val in transactions.values():\n",
        "            itemset.update(val)\n",
        "    else:\n",
        "        prev_itemset_keys = list(itemset.keys())\n",
        "        prev_itemset = itemset.copy()\n",
        "\n",
        "        valid_keys = list(set(itemset.keys()))\n",
        "\n",
        "        l = []\n",
        "        for row in valid_keys:\n",
        "            l.extend(row)\n",
        "\n",
        "        valid_keys = set(l)\n",
        "\n",
        "        # candidate itemset keys\n",
        "        itemset_keys_ = list(combinations(valid_keys, size))\n",
        "\n",
        "        # Apriori algorithm is based on the concept that a subset of a frequent itemset must also be a frequent itemset\n",
        "        # so we are pruning away those features whose subset are not present in the previous frequent itemset\n",
        "        if size >= 2:\n",
        "            itemset_keys_ = _pruning(\n",
        "                itemset_keys_, prev_itemset_keys, size - 1)\n",
        "\n",
        "        # finding support value for each of the selected itemset feature combination\n",
        "        itemset = support_value(itemset_keys_, transactions)\n",
        "\n",
        "        # defaulting back to th previous frequent itemset if\n",
        "        # the iteration doesn't find any itemset which has the theshold required\n",
        "        if itemset == {}:\n",
        "            itemset = prev_itemset\n",
        "\n",
        "    # getting frequent itemset from itemset\n",
        "    # Frequent Itemset is an itemset whose support\n",
        "    # value is greater than a threshold value(support).\n",
        "\n",
        "    frequent_itemset = {}\n",
        "    for key, val in itemset.items():\n",
        "        if val >= min_support_count:\n",
        "            frequent_itemset[key] = val\n",
        "\n",
        "    return frequent_itemset"
      ],
      "metadata": {
        "id": "eg-Jvq3ruds8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to find subset"
      ],
      "metadata": {
        "id": "xFOQPl3kud2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finding_subsets(frequent_set):\n",
        "    item_list = []\n",
        "    size = len(list(frequent_set.keys())[0])\n",
        "    for key in frequent_set.keys():\n",
        "        subsets = []\n",
        "        for i in range(1, size):\n",
        "            subsets.append(list(combinations(key, i)))\n",
        "\n",
        "        subsets = list(np.array(subsets).flatten())\n",
        "        subsets.insert(0, key)\n",
        "        item_list.append(subsets)\n",
        "\n",
        "    return item_list"
      ],
      "metadata": {
        "id": "1ByGJTtOvCyR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function to find rules."
      ],
      "metadata": {
        "id": "taxEe234ueAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finding_rules(itemset_sub):\n",
        "    print(\"Antecedents -->  Consequents --- Confidence\")\n",
        "    for i in range(1, len(itemset_sub)):\n",
        "\n",
        "        # passing as list as we have designed support_value function as\n",
        "        # a function that takes an iteratable list of itemsets\n",
        "        x = support_value([itemset_sub[0], ], transactions)\n",
        "        y = support_value([itemset_sub[i], ], transactions)\n",
        "        confidence = list(x.values())[0] / list(y.values())[0]\n",
        "        if confidence >= min_confidence_value:\n",
        "            print(\n",
        "                f\"{itemset_sub[i]} --> {itemset_sub[0]} --- {round(confidence, 2)}\")"
      ],
      "metadata": {
        "id": "fiRAYSG0ueO1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "    ITEMS\n",
        "    1: Banana\n",
        "    2: Eggs\n",
        "    3: Milk\n",
        "    4: Tea\n",
        "    5: Bread\n",
        "\"\"\")\n",
        "\n",
        "f = {}\n",
        "\n",
        "for i in range(1, 5):\n",
        "    f = get_frequent_itemset(size=i, transactions=transactions,\n",
        "                             itemset=f)\n",
        "\n",
        "# frequent_itemsets\n",
        "\n",
        "print(\"Frequent Itemsets...\")\n",
        "for key, val in f.items():\n",
        "    print(f\"Itemset: {key}, support value: {val}\")\n",
        "\n",
        "\n",
        "subset = finding_subsets(f)\n",
        "\n",
        "for i in subset:\n",
        "    print(f\"Rules for itemset - {i[0]}\")\n",
        "    finding_rules(i)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP0HMI3_X5kX",
        "outputId": "a6cc3c92-b526-47a3-e098-d0b509f8e168"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    ITEMS\n",
            "    1: Banana\n",
            "    2: Eggs\n",
            "    3: Milk\n",
            "    4: Tea\n",
            "    5: Bread\n",
            "\n",
            "Frequent Itemsets...\n",
            "Itemset: ('1', '5', '3'), support value: 2\n",
            "Itemset: ('2', '5', '3'), support value: 2\n",
            "Rules for itemset - ('1', '5', '3')\n",
            "Antecedents -->  Consequents --- Confidence\n",
            "('1',) --> ('1', '5', '3') --- 0.67\n",
            "('1', '5') --> ('1', '5', '3') --- 1.0\n",
            "('1', '3') --> ('1', '5', '3') --- 0.67\n",
            "('5', '3') --> ('1', '5', '3') --- 0.67\n",
            "\n",
            "Rules for itemset - ('2', '5', '3')\n",
            "Antecedents -->  Consequents --- Confidence\n",
            "('2',) --> ('2', '5', '3') --- 0.67\n",
            "('2', '5') --> ('2', '5', '3') --- 0.67\n",
            "('2', '3') --> ('2', '5', '3') --- 1.0\n",
            "('5', '3') --> ('2', '5', '3') --- 0.67\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ]
    }
  ]
}